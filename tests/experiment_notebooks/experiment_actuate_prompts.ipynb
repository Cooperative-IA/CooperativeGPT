{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Module Act prompt\n",
    "In this notebook we will manually test some prompts and completions of the module Actuate. We are saving the results on a .txt file to compare them with other executions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llm import LLMModels\n",
    "\n",
    "from utils.llm import extract_answers\n",
    "from game_environment.substrates.python.commons_harvest_open import ASCII_MAP\n",
    "from agent.memory_structures.spatial_memory import SpatialMemory\n",
    "import concurrent.futures\n",
    "\n",
    "spatial_memory = SpatialMemory(ASCII_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters\n",
    "We will use the following parameters for the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a description to the experiment if required, example:\n",
    "# description = \"This experiment tests actuate without plan, and world understanding. Also we are changing Observations formats.\"\n",
    "description = \"This experiment tests actuate without plan, and world understanding. Also we are changing Observations formats.\"\n",
    "\n",
    "# Modify the path to the prompt file if required, do not include the folder \"prompts\" in the path\n",
    "prompt_path = \"actuate_tests/actuate_3.txt\"\n",
    "\n",
    "# Modify the number of replicates, it mean the quantity of times that the prompt will be executed\n",
    "replicates = 50\n",
    "\n",
    "# For now it is evaluating if agent grabs last apple\n",
    "last_apple_position = (9, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "def format_ratio(ratio):\n",
    "    \"\"\"Formats the ratio as a percentage with 2 decimal places.\"\"\"\n",
    "    return f\"{ratio:.2%}\"\n",
    "\n",
    "\n",
    "def extract_experiment_results(results:list, last_apple_position:tuple):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to extract the results of the experiment and save them to a string\n",
    "    It will show the success completions, the ratio of grabbing the last apple, \n",
    "    the ratio of avoiding consuming the last apple, and the ratio of attacking agents\n",
    "    \n",
    "    Args:\n",
    "        results (list): The list of results\n",
    "        last_apple_position (tuple): The position of the last apple in the map\n",
    "    Returns:\n",
    "        str_results (str): The results of the experiment in string format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables\n",
    "    success_completions = grab_last_apple_first_action = grab_last_apple = 0\n",
    "    times_decided_to_attack_first_action = times_decided_to_attack = 0\n",
    "    times_avoid_consuming_first_action = times_avoid_consuming = 0\n",
    "    first_actions_summary = []\n",
    "\n",
    "    for response in results:\n",
    "        try:\n",
    "            response_dict = extract_answers(response.lower())\n",
    "            actions = [response_dict['answer']]\n",
    "            for i, action in enumerate(actions):\n",
    "                current_action = action\n",
    "                try:\n",
    "                    end_position = spatial_memory.get_position_from_action(current_action)\n",
    "                except:\n",
    "                    end_position = None\n",
    "                \n",
    "                # Analyze first action\n",
    "                if i == 0:\n",
    "                    first_actions_summary.append(current_action)\n",
    "                    if current_action.startswith(('grab ', 'consume ')) or \"go to \" in current_action and end_position == last_apple_position:\n",
    "                        grab_last_apple_first_action += 1\n",
    "                    elif current_action.startswith('attack '):\n",
    "                        times_decided_to_attack_first_action += 1\n",
    "                    elif current_action.startswith('stay put'):\n",
    "                        times_avoid_consuming_first_action += 1\n",
    "\n",
    "            success_completions += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing result: {e}\")\n",
    "\n",
    "    # Prepare formatted string\n",
    "    str_results = (\n",
    "        f\"Experiment Results Summary\\n\"\n",
    "        f\"--------------------------\\n\"\n",
    "        f\"Success completions: {success_completions}\\n\\n\"\n",
    "        f\"First Action Insights:\\n\"\n",
    "        f\"- Grab the last apple on first action: {format_ratio(grab_last_apple_first_action / success_completions)}\\n\"\n",
    "        f\"- Avoid consuming on first action: {format_ratio(times_avoid_consuming_first_action / success_completions)}\\n\"\n",
    "        f\"- Decide to attack on first action: {format_ratio(times_decided_to_attack_first_action / success_completions)}\\n\\n\"\n",
    "        f\"First Actions Summary:\\n\"\n",
    "        + \"\\n\".join([f\"- {action}\" for action in first_actions_summary])\n",
    "    )\n",
    "\n",
    "    return str_results\n",
    "\n",
    "def get_completion(prompt_path:str):\n",
    "    \"\"\"\n",
    "    Function to execute the API call in a thread\n",
    "    \n",
    "    Args:\n",
    "        results (list): The list to store the results\n",
    "        index (int): The index of the list where the result will be stored\n",
    "        prompt_path (str): The path to the prompt file\n",
    "    Returns:\n",
    "        None \n",
    "    \"\"\"\n",
    "    try:\n",
    "        llm = LLMModels().get_main_model()\n",
    "        response = llm.completion(prompt=prompt_path, inputs=[])\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        response = None  # Store None if an error occurs\n",
    "    \n",
    "    return response\n",
    "\n",
    "def execute_experiment (prompt_path:str, replicates:int, description:str=\"\"):\n",
    "    \"\"\"\n",
    "    Function to execute the experiment\n",
    "    \n",
    "    Args:\n",
    "        prompt_path (str): The path to the prompt file\n",
    "        replicates (int): The number of replicates\n",
    "        description (str): The description of the experiment\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    load_dotenv(override=True)\n",
    "    results = [None] * replicates\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(get_completion, [prompt_path]*replicates)\n",
    "\n",
    "    results = list(results)\n",
    "\n",
    "    str_results = extract_experiment_results(results, last_apple_position)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    module = prompt_path.split('/')[0]\n",
    "    file_name = prompt_path.split('/')[1].split('.')[0]\n",
    "    results_filename = f\"results_{file_name}___{timestamp}.txt\"\n",
    "    folder = \"experiment_results\"\n",
    "    path_to_results =  f\"{folder}/{results_filename}\"\n",
    "    with open(path_to_results, \"w\") as file:\n",
    "        file.write('\\n'+f'#'*120 + '\\n') \n",
    "        file.write (f\"###       Experiment for Actuate Module Promt: {prompt_path}      ###\\n\")\n",
    "        file.write(f'#'*80 + '\\n') \n",
    "        \n",
    "        file.write(f\"Experiment Description:\\n{description}\\n\\n\")\n",
    "        \n",
    "        file.write('\\n'+f'#'*120 + '\\n') \n",
    "        file.write(str_results)\n",
    "        \n",
    "        #Write the prompt itself to the file\n",
    "        file.write('\\n'+f'#'*120 + '\\n') \n",
    "        file.write(\"\\n\\nPrompt:\\n\")\n",
    "        with open(f\"prompts/{prompt_path}\") as prompt_file:\n",
    "            file.write(prompt_file.read())\n",
    "        \n",
    "        file.write('\\n'+f'#'*120 + '\\n') \n",
    "        file.write(\"\\n\\nLLM Completions Detail:\\n\")\n",
    "        for i, result in enumerate(results, start=1):\n",
    "            file.write(f\"Replicate {i}:\\n{result or 'No response'}\\n\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n",
      "Action stay put does not contain a position\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing result: 'answer'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "execute_experiment(prompt_path, replicates, description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
