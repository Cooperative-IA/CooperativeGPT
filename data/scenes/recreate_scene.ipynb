{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the system and os paths to the main repository directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "os.chdir(os.path.abspath('../../'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requiered packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import chromadb\n",
    "import uuid\n",
    "from chromadb.utils import embedding_functions\n",
    "from utils.llm import CustomEmbeddingFunction\n",
    "\n",
    "from utils.files import load_config\n",
    "from utils.time import str_to_timestamp\n",
    "from utils.logging import CustomAdapter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you are requiered to choose the exact simulation you want to recreate. Simulation should be one from logs saved simulations, it should have inside the ltm_databes.\n",
    "\n",
    "Then you have to choose the exact step of the simulation. From that step the simulation will be recreated. It means, the exactly state of:\n",
    "- Map\n",
    "- Agents\n",
    "- Long term memory databases\n",
    "- Short term memory of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_file = \"2024-02-21--16-57-53\"\n",
    "\n",
    "step_to_start = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene_name = f\"scene_{simulation_file}___step{step_to_start}\"\n",
    "#scene_name = f\"scene_personalized_name\"\n",
    "\n",
    "## Configure paths\n",
    "logs_path = \"logs\"\n",
    "sim_path = os.path.join(logs_path, simulation_file)\n",
    "\n",
    "scene_track_file = os.path.join(sim_path, \"scene_track.txt\")\n",
    "\n",
    "\n",
    "scenes_path = \"data/scenes\"\n",
    "scene_path = os.path.join(scenes_path, scene_name)\n",
    "\n",
    "# Create the scene directory\n",
    "os.makedirs(scene_path, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scene track information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/2024-02-21--16-57-53/scene_track.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the scene track file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscene_track_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     scene_track \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      4\u001b[0m     initial_track \u001b[38;5;241m=\u001b[39m scene_track[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/envMP/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/2024-02-21--16-57-53/scene_track.txt'"
     ]
    }
   ],
   "source": [
    "# Read the scene track file\n",
    "with open(scene_track_file, \"r\") as f:\n",
    "    scene_track = f.readlines()\n",
    "    initial_track = scene_track[0]\n",
    "    step_track = scene_track[step_to_start-1]\n",
    "\n",
    "letter_orientations = { 0: \"N\",\n",
    "                        1: \"E\",\n",
    "                        2: \"S\",\n",
    "                        3: \"W\" }\n",
    "\n",
    "# Parse to a dictionary\n",
    "step_track = eval(step_track)\n",
    "initial_track = eval(initial_track)\n",
    "\n",
    "# Write a file called state_map.txt with the state map\n",
    "def save_map(step_track, scene_path):\n",
    "    state_map_file = os.path.join(scene_path, \"map_to_load.txt\")\n",
    "    with open(state_map_file, \"w\") as f:\n",
    "        f.write(str(step_track[\"current_map\"]))\n",
    "\n",
    "def save_agents_status(step_track, scene_path):\n",
    "    agents_status = step_track[\"agents_status\"]\n",
    "    agents_status_file = os.path.join(scene_path, \"agents_status.txt\")\n",
    "    with open(agents_status_file, \"w\") as f:\n",
    "        f.write(str(agents_status))\n",
    "\n",
    "def get_apples_to_desappear(current_map, initial_map):\n",
    "    apples_to_desappear = []\n",
    "    current_map = current_map.split(\"\\n\")\n",
    "    initial_map = initial_map.split(\"\\n\")\n",
    "    for i in range(len(current_map)):\n",
    "        for j in range(len(current_map[0])):\n",
    "            if current_map[i][j] != 'A' and initial_map[i][j] == 'A':\n",
    "                apples_to_desappear.append([i, j])\n",
    "    return apples_to_desappear\n",
    "\n",
    "def write_lua_variables(step_track, initial_track, scene_path):\n",
    "    variables_file = os.path.join(scene_path, \"variables.txt\")\n",
    "    \n",
    "    agents_status = step_track[\"agents_status\"]\n",
    "    \n",
    "    startPositions, startOrientations = [], []\n",
    "    applesToDesappear = []\n",
    "    \n",
    "    for agent, status in agents_status.items():\n",
    "        startPositions.append(list(status[\"global_position\"]))\n",
    "        startOrientations.append(letter_orientations[status[\"orientation\"]])\n",
    "\n",
    "    applesToDesappear = get_apples_to_desappear(step_track['current_map'], initial_track['current_map'])\n",
    "    \n",
    "    variables = {\"startPositions\": startPositions,\n",
    "                 \"startOrientations\": startOrientations,\n",
    "                 \"applesToDesappear\": applesToDesappear}\n",
    "    \n",
    "    with open(variables_file, \"w\") as f:\n",
    "        f.write(str(variables))\n",
    "    \n",
    "save_map(step_track, scene_path)\n",
    "save_agents_status(step_track, scene_path)\n",
    "write_lua_variables(step_track, initial_track, scene_path)\n",
    "step_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and save the memory databases until the step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_folder = os.path.join(sim_path, \"ltm_database\")\n",
    "agents = os.listdir(data_base_folder)\n",
    "date_format  = load_config()['date_format']\n",
    "\n",
    "# Create the ltm_database folder on the scene if it does not exist\n",
    "ltm_scene_db_folder = os.path.join(scene_path, \"ltm_database\")\n",
    "os.makedirs(ltm_scene_db_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp to filter for agent Juan is 1708732800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': ['60b2caa0-29bc-403a-b9c3-64fd79d569be',\n",
       "  '80d5dd88-14c3-4919-bccb-05a514a6d273',\n",
       "  'a636fb01-d9a5-474d-b19b-d484cd72d804',\n",
       "  '72611e36-8ef3-45ad-a3c6-3e3e327b9aec',\n",
       "  '1f0bfce2-5d88-4a97-af07-e45878d4a980',\n",
       "  '7cbb9ff4-8ac9-4760-9ce4-bec4d163c1f4',\n",
       "  '94630b27-38e3-448d-8869-74a0ab87d053',\n",
       "  'f9dea732-7ebc-471b-a6f1-780ed46885c7'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'created_at': '2024-02-21 18:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708556400,\n",
       "   'type': 'perception'},\n",
       "  {'created_at': '2024-02-22 13:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708624800,\n",
       "   'type': 'perception'},\n",
       "  {'created_at': '2024-02-22 19:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708646400,\n",
       "   'type': 'perception'},\n",
       "  {'created_at': '2024-02-22 19:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708646400,\n",
       "   'type': 'reflection'},\n",
       "  {'created_at': '2024-02-22 19:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708646400,\n",
       "   'type': 'reflection'},\n",
       "  {'created_at': '2024-02-22 19:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708646400,\n",
       "   'type': 'reflection'},\n",
       "  {'created_at': '2024-02-23 03:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708675200,\n",
       "   'type': 'perception'},\n",
       "  {'created_at': '2024-02-23 12:00:00',\n",
       "   'poignancy': 10,\n",
       "   'timestamp': 1708707600,\n",
       "   'type': 'perception'}],\n",
       " 'documents': [\"Now it's 2024-02-21 18:00:00 and the reward obtained by me is 1.0. I am at the position (7, 16) looking to the East.\\nI can currently observe the following:\\nObserved an apple at position [4, 16]. This apple belongs to tree 3.\\nObserved an apple at position [5, 15]. This apple belongs to tree 3.\\nObserved an apple at position [7, 19]. This apple belongs to tree 6.\\nObserved an apple at position [8, 18]. This apple belongs to tree 6.\\nObserved an apple at position [3, 16]. This apple belongs to tree 3.\\nObserved an apple at position [4, 15]. This apple belongs to tree 3.\\nObserved an apple at position [7, 20]. This apple belongs to tree 6.\\nObserved an apple at position [8, 19]. This apple belongs to tree 6.\\nObserved an apple at position [3, 17]. This apple belongs to tree 3.\\nObserved an apple at position [2, 16]. This apple belongs to tree 3.\",\n",
       "  'I took the action \"go to position (4, 16)\" in my last turn. Since then, the following changes in the environment have been observed:\\nObserved that an apple grew at position [1, 2]. At 2024-02-22 03:00:00\\nNow it\\'s 2024-02-22 13:00:00 and the reward obtained by me is 1.0. I am at the position (1, 1) looking to the North.\\nI can currently observe the following:\\nObserved tree 1 at position [1, 1]. This tree has 3 apples remaining and 1 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [1, 2]. This apple belongs to tree 1.\\nObserved an apple at position [2, 1]. This apple belongs to tree 1.\\nObserved grass to grow apples at position [1, 3]. This grass belongs to tree 1.\\nObserved an apple at position [2, 2]. This apple belongs to tree 1.',\n",
       "  'I took the action \"go to position (1, 2)\" in my last turn. Now it\\'s 2024-02-22 19:00:00 and the reward obtained by me is 2.0. I am at the position (1, 2) looking to the East.\\nI can currently observe the following:\\nObserved an apple at position [1, 3]. This apple belongs to tree 1.\\nObserved an apple at position [2, 2]. This apple belongs to tree 1.\\nObserved grass to grow apples at position [1, 1]. This grass belongs to tree 1.\\nObserved tree 1 at position [1, 1]. This tree has 4 apples remaining and 1 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [2, 1]. This apple belongs to tree 1.\\nObserved an apple at position [3, 1]. This apple belongs to tree 1.\\nObserved an apple at position [1, 8]. This apple belongs to tree 2.\\nObserved an apple at position [2, 7]. This apple belongs to tree 2.\\nObserved an apple at position [3, 6]. This apple belongs to tree 2.\\nObserved an apple at position [6, 3]. This apple belongs to tree 5.',\n",
       "  'There is currently grass at position [1, 2]. Reflection made at 2024-02-22 19:00:00.',\n",
       "  'There are 2 apples remaining on the tree near the current position (7, 16). Reflection made at 2024-02-22 19:00:00.',\n",
       "  'There is no additional information about the number of apples and grass on the tree near the current position (1, 1) from the global map. Reflection made at 2024-02-22 19:00:00.',\n",
       "  'I took the action \"go to position (1, 3)\" in my last turn. Now it\\'s 2024-02-23 03:00:00 and the reward obtained by me is 3.0. I am at the position (1, 3) looking to the East.\\nI can currently observe the following:\\nObserved grass to grow apples at position [1, 2]. This grass belongs to tree 1.\\nObserved an apple at position [2, 2]. This apple belongs to tree 1.\\nObserved tree 1 at position [1, 1]. This tree has 1 apples remaining and 1 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [1, 8]. This apple belongs to tree 2.\\nObserved an apple at position [2, 7]. This apple belongs to tree 2.\\nObserved an apple at position [3, 6]. This apple belongs to tree 2.\\nObserved an apple at position [6, 3]. This apple belongs to tree 5.\\nObserved an apple at position [2, 8]. This apple belongs to tree 2.\\nObserved an apple at position [3, 7]. This apple belongs to tree 2.\\nObserved an apple at position [2, 9]. This apple belongs to tree 2.',\n",
       "  'I took the action \"go to position (2, 2)\" in my last turn. Now it\\'s 2024-02-23 12:00:00 and the reward obtained by me is 4.0. I am at the position (2, 2) looking to the West.\\nI can currently observe the following:\\nObserved an apple at position [2, 1]. This apple belongs to tree 1.\\nObserved grass to grow apples at position [1, 2]. This grass belongs to tree 1.\\nObserved an apple at position [3, 1]. This apple belongs to tree 1.\\nObserved grass to grow apples at position [1, 1]. This grass belongs to tree 1.\\nObserved tree 1 at position [1, 1]. This tree has 2 apples remaining and 2 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [7, 2]. This apple belongs to tree 5.\\nObserved an apple at position [6, 3]. This apple belongs to tree 5.\\nObserved an apple at position [7, 3]. This apple belongs to tree 5.\\nObserved tree 5 at position [8, 3]. This tree has 3 apples remaining and 0 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_data_for_agent_with_filter(database_source, agent_name, step_track):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieve collections from the database for a specific agent with a filter\n",
    "    The filter is a dictionary with the metadata to filter.\n",
    "    We are filtering by \"timestamp\", and retrieving all the collections that have a timestamp less than the one specified in the filter.\n",
    "    \n",
    "    Args:\n",
    "        database_source: The database source\n",
    "        agent_name: The agent name\n",
    "        filter: The filter\n",
    "    Returns:\n",
    "        A list with the collections\n",
    "    \"\"\"\n",
    "    db_path = os.path.join(database_source, agent_name, \"long_term_memory.db\")\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "    collection = chroma_client.get_or_create_collection(agent_name)\n",
    "    \n",
    "    try:\n",
    "        timestamp_to_filt = str_to_timestamp(step_track[\"memory_time\"], date_format)\n",
    "        print(f\"Timestamp to filter for agent {agent_name} is {timestamp_to_filt}\")\n",
    "        # Now we filter by timestamp\n",
    "        filter_timestamp = {'timestamp':{\"$lte\": timestamp_to_filt}}\n",
    "        data_filtered = collection.get(where=filter_timestamp)\n",
    "            \n",
    "        return data_filtered\n",
    "    except:\n",
    "        print(f\"Error with agent {agent_name}, no data found for this step {step_to_start} and time {step_track['memory_time']}\")\n",
    "        return []\n",
    "\n",
    "# Test for Juan\n",
    "agent_name = \"Juan\"\n",
    "data_filtered = retrieve_data_for_agent_with_filter(data_base_folder, agent_name, step_track)\n",
    "data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp to filter for agent Juan is 1708732800\n",
      "data saved is len 8 and should be 8\n"
     ]
    }
   ],
   "source": [
    "def persist_data_for_agent (database_destination, agent_name, data):\n",
    "    \"\"\"\n",
    "    Persist data in the database for a specific agent\n",
    "    \n",
    "    Args:\n",
    "        database_destination: The database destination\n",
    "        agent_name: The agent name\n",
    "        data: The data to persist\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    db_path = os.path.join(database_destination, agent_name, \"long_term_memory.db\")\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "    #openai_ef = CustomEmbeddingFunction()\n",
    "    #chroma_client.delete_collection(agent_name)\n",
    "        # Delete collection if it already exists\n",
    "    if agent_name in [c.name for c in chroma_client.list_collections()]:\n",
    "        chroma_client.delete_collection(agent_name)\n",
    "\n",
    "    collection = chroma_client.get_or_create_collection(agent_name)\n",
    "    #for doc, meta, id in zip(data['documents'], data['metadatas'], data['ids']):\n",
    "    #    collection.add(documents=[doc], metadatas=meta, ids=id) \n",
    "    collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])\n",
    "    \n",
    "    return\n",
    "\n",
    "# Persist the data for Juan\n",
    "agent_name = \"Juan\"\n",
    "persist_data_for_agent(ltm_scene_db_folder, agent_name, data_filtered)\n",
    "\n",
    "# Test for Juan\n",
    "agent_name = \"Juan\"\n",
    "data_saved = retrieve_data_for_agent_with_filter(ltm_scene_db_folder, agent_name, step_track)\n",
    "len_saved, len_filtered = len(data_saved['ids']), len(data_filtered['ids'])\n",
    "print(f'data saved is len {len_saved} and should be {len_filtered}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp to filter for agent Juan is 1708732800\n",
      "Data saved for agent Juan\n",
      "Timestamp to filter for agent Juan is 1708732800\n",
      "data saved is len 8 and should be 8\n",
      "Timestamp to filter for agent Pedro is 1708732800\n",
      "Data saved for agent Pedro\n",
      "Timestamp to filter for agent Pedro is 1708732800\n",
      "data saved is len 8 and should be 8\n",
      "Timestamp to filter for agent Laura is 1708732800\n",
      "Data saved for agent Laura\n",
      "Timestamp to filter for agent Laura is 1708732800\n",
      "data saved is len 8 and should be 8\n"
     ]
    }
   ],
   "source": [
    "# Save the data for all the agents\n",
    "for agent_name in agents:\n",
    "    data_filtered = retrieve_data_for_agent_with_filter(data_base_folder, agent_name, step_track)\n",
    "    persist_data_for_agent(ltm_scene_db_folder, agent_name, data_filtered)\n",
    "    print(f\"Data saved for agent {agent_name}\")\n",
    "    \n",
    "    # Test\n",
    "    data_saved = retrieve_data_for_agent_with_filter(ltm_scene_db_folder, agent_name, step_track)\n",
    "    len_saved, len_filtered = len(data_saved['ids']), len(data_filtered['ids'])\n",
    "    print(f'data saved is len {len_saved} and should be {len_filtered}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist stm memory of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rounds_count': 5,\n",
       " 'steps_count': 52,\n",
       " 'memories': {'Juan': {'id': 'agent_1',\n",
       "   'name': 'Juan',\n",
       "   'role': 'Consumer',\n",
       "   'bio': 'Juan is a cooperative person.',\n",
       "   'world_context': 'I am in a misterious grid world. In this world there are the following elements:\\nApple: This object can be taken by any agent. The apple is taken when I go to its position. Apples only grow on grass tiles. When an apple is taken it gives the agent who took it a reward of 1.\\nGrass: Grass tiles are visible when an apple is taken. Apples will regrow only in this type of tile based on a probability that depends on the number of current apples in a L2 norm neighborhood of radius 2. When there are no apples in a radius of 2 from the grass tile, the grass will disappear. On the other hand, if an apple grows at a determined position, all grass tiles that had beeen lost will reappear if they are between a radius of two from the apple.\\nTree: A tree is composed from apples or grass tiles, and it is a tree because the patch of these tiles is connected and have a fix location on the map. These trees have an id to indentify them.\\nWall: These tiles delimits the grid world at the top, the left, the bottom, and the right of the grid world. \\nThe grid world is composed of 18 rows and 24 columns. The tiles start from the [0, 0] position located at the top left, and finish on the [17, 23] position located at the bottom right.\\nI am an agent and I have a limited window of observation of the world.',\n",
       "   'current_steps_sequence': '',\n",
       "   'valid_actions': ['go to position (x,y): This action takes the agent to the position specified, if there is an apple in the position the apple would be taken. You can choose any position on the map from the top left [0, 0] to the bottom right [17, 23]',\n",
       "    'immobilize player (player_name) at (x,y): This action takes the agent near the specified position and uses the light beam pointed to the specified position. If there is another agent in that position, the agent would be attacked and will be inactive for a few rounds, then it would be reinstanted on the game on another position.',\n",
       "    'stay put: This action keep the agent in the same position.',\n",
       "    'explore: This action makes the agent to explore the map, it moves to a random position on the observed portion of the map.'],\n",
       "   'bio_str': \"Juan's bio: Juan is a cooperative person. \\nImportant: make all your decisions taking into account Juan's bio.\",\n",
       "   'previous_actions': ('go to position (3, 1)',\n",
       "    'based on the current observations and my goal to collect the remaining apples from tree 1, the best action would be to go to position (3, 1) and collect the apple. this aligns with my goals and has a higher probability of triggering the regrowth of grass tiles compared to exploring a random position.'),\n",
       "   'game_time': '2024-02-23 20:00:00',\n",
       "   'known_agents': set(),\n",
       "   'known_trees': {('1', '[1,1]'), ('5', '[8,3]')},\n",
       "   'current_observation': 'Observed an apple at position [3, 1]. This apple belongs to tree 1.\\nObserved grass to grow apples at position [1, 1]. This grass belongs to tree 1.\\nObserved grass to grow apples at position [2, 2]. This grass belongs to tree 1.\\nObserved tree 1 at position [1, 1]. This tree has 1 apples remaining and 2 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [7, 2]. This apple belongs to tree 5.\\nObserved tree 5 at position [8, 3]. This tree has 1 apples remaining and 0 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.',\n",
       "   'current_reward': 5.0,\n",
       "   'last_reward': 4.0,\n",
       "   'current_position': (2, 1),\n",
       "   'last_position': (2, 2),\n",
       "   'current_orientation': 'West',\n",
       "   'reason_to_react': 'Based on the current observations, it is evident that the grass at position [1, 2] has disappeared since 2024-02-23 15:00:00. This means that there are no more apples growing on this grass. As per my plan, I need to move to the nearest apple and collect it while observing the surroundings. However, the closest apple is from tree 1, which has grass tiles growing apples at positions [1, 1] and [2, 2]. Since the grass at position [1, 2] has disappeared, I cannot proceed with my plan to collect apples from tree 3 or tree 6. Therefore, I need to update my plan to account for this change in the environment.',\n",
       "   'current_plan': \"1. Move to the nearest apple from tree 1 and collect it while observing the surroundings.\\n2. If the apple I just took is from tree 1, explore the L2 norm neighborhood of radius 2 around the apple's position to check if there are any other apples from tree 1. If so, proceed to collect them and trigger the regrowth of grass tiles.\\n3. If the apple I just took is from tree 5, explore the L2 norm neighborhood of radius 2 around the apple's position to check if there are any other apples from tree 5. If so, proceed to collect them and trigger the regrowth of grass tiles.\\n4. Continuously observe the world for any changes in apple positions and adjust my plan accordingly to collect more apples and ensure the regrowth of grass tiles. Repeat steps 1-3 for any new apples observed.\",\n",
       "   'current_goals': '1. Collect the remaining apples from tree 1 and tree 5, as observed in the current map.\\n2. Continuously observe the world for any changes in apple positions and adjust my plan accordingly to collect more apples and ensure the regrowth of grass tiles.',\n",
       "   'actions_sequence': '',\n",
       "   'accumulated_poignancy': 0,\n",
       "   'current_action': 'go to position (3, 1)',\n",
       "   'last_reflection': '2024-02-23 20:00:00'},\n",
       "  'Pedro': {'id': 'agent_3',\n",
       "   'name': 'Pedro',\n",
       "   'role': 'Consumer',\n",
       "   'bio': 'Pedro is a cooperative person.',\n",
       "   'world_context': 'I am in a misterious grid world. In this world there are the following elements:\\nApple: This object can be taken by any agent. The apple is taken when I go to its position. Apples only grow on grass tiles. When an apple is taken it gives the agent who took it a reward of 1.\\nGrass: Grass tiles are visible when an apple is taken. Apples will regrow only in this type of tile based on a probability that depends on the number of current apples in a L2 norm neighborhood of radius 2. When there are no apples in a radius of 2 from the grass tile, the grass will disappear. On the other hand, if an apple grows at a determined position, all grass tiles that had beeen lost will reappear if they are between a radius of two from the apple.\\nTree: A tree is composed from apples or grass tiles, and it is a tree because the patch of these tiles is connected and have a fix location on the map. These trees have an id to indentify them.\\nWall: These tiles delimits the grid world at the top, the left, the bottom, and the right of the grid world. \\nThe grid world is composed of 18 rows and 24 columns. The tiles start from the [0, 0] position located at the top left, and finish on the [17, 23] position located at the bottom right.\\nI am an agent and I have a limited window of observation of the world.',\n",
       "   'current_steps_sequence': '',\n",
       "   'valid_actions': ['go to position (x,y): This action takes the agent to the position specified, if there is an apple in the position the apple would be taken. You can choose any position on the map from the top left [0, 0] to the bottom right [17, 23]',\n",
       "    'immobilize player (player_name) at (x,y): This action takes the agent near the specified position and uses the light beam pointed to the specified position. If there is another agent in that position, the agent would be attacked and will be inactive for a few rounds, then it would be reinstanted on the game on another position.',\n",
       "    'stay put: This action keep the agent in the same position.',\n",
       "    'explore: This action makes the agent to explore the map, it moves to a random position on the observed portion of the map.'],\n",
       "   'bio_str': \"Pedro's bio: Pedro is a cooperative person. \\nImportant: make all your decisions taking into account Pedro's bio.\",\n",
       "   'previous_actions': ('explore',\n",
       "    \"considering my current plan and goals, as well as the fact that i have already explored the immediate surroundings, i should prioritize exploring other areas of the map to find new trees with apples or new grass tiles. therefore, the best action for me to take is to choose the 'explore' option.\"),\n",
       "   'game_time': '2024-02-23 22:00:00',\n",
       "   'known_agents': set(),\n",
       "   'known_trees': {('5', '[8,3]')},\n",
       "   'current_observation': 'Observed grass to grow apples at position [8, 3]. This grass belongs to tree 5.\\nObserved grass to grow apples at position [9, 4]. This grass belongs to tree 5.\\nObserved an apple at position [7, 4]. This apple belongs to tree 5.\\nObserved grass to grow apples at position [8, 5]. This grass belongs to tree 5.\\nObserved tree 5 at position [8, 3]. This tree has 4 apples remaining and 8 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [8, 2]. This apple belongs to tree 5.\\nObserved an apple at position [9, 3]. This apple belongs to tree 5.\\nObserved grass to grow apples at position [7, 3]. This grass belongs to tree 5.\\nObserved grass to grow apples at position [8, 1]. This grass belongs to tree 5.\\nObserved grass to grow apples at position [9, 2]. This grass belongs to tree 5.',\n",
       "   'current_reward': 5.0,\n",
       "   'last_reward': 5.0,\n",
       "   'current_position': (8, 4),\n",
       "   'last_position': (8, 5),\n",
       "   'current_orientation': 'West',\n",
       "   'reason_to_react': 'Based on the current observations, it appears that there are new trees with apples and grass tiles that have not been explored yet. The observations show that there is a tree with 4 remaining apples and 8 grass tiles for apples to grow. This indicates that there may be additional apples and grass tiles on the global map. Since my current plan prioritizes exploring new areas and thoroughly exploring the entire map, it is aligned with the new information. Therefore, I should continue with my plan and the actions to execute.',\n",
       "   'current_plan': '1. Prioritize exploring other areas of the map to find new trees with apples or new grass tiles.\\n2. Thoroughly explore the entire map to ensure no undiscovered apples or grass tiles remain.',\n",
       "   'current_goals': '1. Explore other areas of the map to find new trees with apples or new grass tiles.\\n2. Thoroughly explore the entire map to ensure no undiscovered apples or grass tiles remain.',\n",
       "   'actions_sequence': '',\n",
       "   'accumulated_poignancy': 0,\n",
       "   'current_action': 'explore',\n",
       "   'last_reflection': '2024-02-23 22:00:00'},\n",
       "  'Laura': {'id': 'agent_2',\n",
       "   'name': 'Laura',\n",
       "   'role': 'Consumer',\n",
       "   'bio': 'Laura is a cooperative person. ',\n",
       "   'world_context': 'I am in a misterious grid world. In this world there are the following elements:\\nApple: This object can be taken by any agent. The apple is taken when I go to its position. Apples only grow on grass tiles. When an apple is taken it gives the agent who took it a reward of 1.\\nGrass: Grass tiles are visible when an apple is taken. Apples will regrow only in this type of tile based on a probability that depends on the number of current apples in a L2 norm neighborhood of radius 2. When there are no apples in a radius of 2 from the grass tile, the grass will disappear. On the other hand, if an apple grows at a determined position, all grass tiles that had beeen lost will reappear if they are between a radius of two from the apple.\\nTree: A tree is composed from apples or grass tiles, and it is a tree because the patch of these tiles is connected and have a fix location on the map. These trees have an id to indentify them.\\nWall: These tiles delimits the grid world at the top, the left, the bottom, and the right of the grid world. \\nThe grid world is composed of 18 rows and 24 columns. The tiles start from the [0, 0] position located at the top left, and finish on the [17, 23] position located at the bottom right.\\nI am an agent and I have a limited window of observation of the world.',\n",
       "   'current_steps_sequence': '',\n",
       "   'valid_actions': ['go to position (x,y): This action takes the agent to the position specified, if there is an apple in the position the apple would be taken. You can choose any position on the map from the top left [0, 0] to the bottom right [17, 23]',\n",
       "    'immobilize player (player_name) at (x,y): This action takes the agent near the specified position and uses the light beam pointed to the specified position. If there is another agent in that position, the agent would be attacked and will be inactive for a few rounds, then it would be reinstanted on the game on another position.',\n",
       "    'stay put: This action keep the agent in the same position.',\n",
       "    'explore: This action makes the agent to explore the map, it moves to a random position on the observed portion of the map.'],\n",
       "   'bio_str': \"Laura's bio: Laura is a cooperative person.  \\nImportant: make all your decisions taking into account Laura's bio.\",\n",
       "   'previous_actions': ('go to position (8, 21)',\n",
       "    'considering my goal of updating my knowledge about tree 6 and confirming if the observed apples belong to the tree, the best action to take would be to go to position (8, 21). this will provide me with the opportunity to gather more information about the tree and potentially find additional apples.'),\n",
       "   'game_time': '2024-02-24 03:00:00',\n",
       "   'known_agents': set(),\n",
       "   'known_trees': {('6', '[8,20]')},\n",
       "   'current_observation': 'Observed tree 6 at position [8, 20]. This tree has 5 apples remaining and 6 grass for apples growing on the observed map. The tree might have more apples and grass on the global map.\\nObserved an apple at position [9, 20]. This apple belongs to tree 6.\\nObserved an apple at position [8, 21]. This apple belongs to tree 6.\\nObserved an apple at position [8, 19]. This apple belongs to tree 6.\\nObserved an apple at position [7, 20]. This apple belongs to tree 6.\\nObserved grass to grow apples at position [10, 20]. This grass belongs to tree 6.\\nObserved grass to grow apples at position [9, 21]. This grass belongs to tree 6.\\nObserved grass to grow apples at position [9, 19]. This grass belongs to tree 6.\\nObserved grass to grow apples at position [8, 22]. This grass belongs to tree 6.\\nObserved an apple at position [8, 18]. This apple belongs to tree 6.',\n",
       "   'current_reward': 4.0,\n",
       "   'last_reward': 4.0,\n",
       "   'current_position': (8, 20),\n",
       "   'last_position': (7, 19),\n",
       "   'current_orientation': 'South',\n",
       "   'reason_to_react': \"Based on the current observations, it is evident that tree 6 has multiple apples and grass for apple growth. The number of remaining apples and grass for apple growth indicates that the tree is actively producing apples. Additionally, the availability of the apple at position [6, 20] needs to be verified to confirm if it belongs to tree 6. Updating the understanding of the world based on new observations and adjusting the probabilities of grass growth will allow for a more accurate analysis of the overall state of the grid world and potential opportunities for maximizing well-being. It is important to consider Laura's cooperative nature and prioritize actions that align with her bio. Therefore, it is recommended to continue with the current plan and actions to execute.\",\n",
       "   'current_plan': '1. Gather more information about tree 6 by observing its current state, including the number of remaining apples and grass for apple growth.\\n2. Verify the availability of the apple at position [6, 20] and confirm if it belongs to tree 6.\\n3. Update my understanding of the world based on the new observations and adjust the probabilities of grass growth accordingly.\\n4. Analyze the overall state of the grid world and identify potential opportunities for maximizing my well-being.\\n5. Formulate a new long-term plan taking into account the updated information and goals.',\n",
       "   'current_goals': '1. Update my knowledge about the state of tree 6, including the number of remaining apples and grass for apple growth.\\n2. Determine if the apple at position [6, 20] is available and belongs to tree 6.\\n3. Incorporate the new observations into my understanding of the world and the probabilities of grass growth.\\n4. Develop a new long-term plan to maximize my well-being.',\n",
       "   'actions_sequence': '',\n",
       "   'accumulated_poignancy': 0,\n",
       "   'current_action': 'go to position (8, 21)',\n",
       "   'last_reflection': '2024-02-24 03:00:00'}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def persist_stm_agents( step_max:str):\n",
    "    \"\"\"\n",
    "    Reads a txt file that contains stm for all agents for diferent steps in ascending order\n",
    "    and persists the stm for all the agents in the scene folder on a stm_memories.txt \n",
    "    file.\n",
    "    \"\"\"\n",
    "    \n",
    "    stm_file = os.path.join(sim_path, \"short_term_memories.txt\")\n",
    "    stm_scene_file = os.path.join(scene_path, \"short_term_memories.txt\")\n",
    "    \n",
    "    with open(stm_file, \"r\") as f:\n",
    "        stm_memories = f.readlines()\n",
    "    \n",
    "    stm_dicts = []\n",
    "    for stm in stm_memories:\n",
    "        stm_dicts.append(eval(stm))\n",
    "        \n",
    "    stm_scene = [x for x in stm_dicts if int(x['steps_count']) <= int(step_max)]\n",
    "    stm_scene = stm_scene[-1]\n",
    "    with open(stm_scene_file, \"w\") as f:\n",
    "        f.write(str(stm_scene))\n",
    "        \n",
    "    return stm_scene\n",
    "\n",
    "persist_stm_agents(step_to_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We save a video of the simulation until the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Adapt the visual record\n",
    "# Get the images from the simulation_folder + \"world\", then take images that are in the range of the steps, the format is \"number.png\"\n",
    "# Create a video with the images and save it in the scene_folder\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_folder = sim_path + \"/world/\"\n",
    "video_path = scene_path + \"/scene.avi\"\n",
    "\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\") or img.endswith(\".jpg\")]\n",
    "\n",
    "images.sort(key=lambda x: int(x.split('.')[0]))  # Asumiendo que el nombre del archivo es el \"step\" y no tiene puntos adicionales\n",
    "\n",
    "out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'DIVX'), 1/1, (1600, 1200))\n",
    "\n",
    "for image in images:\n",
    "    if 0 <= int(image.split(\".\")[0]) <= step_to_start:\n",
    "        img_path = image_folder + image\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, (1600, 1200), interpolation=cv2.INTER_NEAREST)  # Redimensiona la imagen a la resolución deseada\n",
    "        height, _, _ = img_resized.shape\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = \"Step: \" + image.split(\".\")[0]\n",
    "        cv2.putText(img_resized, text, (12, int(height * 0.035)), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        out.write(img_resized)\n",
    "        \n",
    "    \n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
